divolte {
  server {
    host = localhost
    host = ${?DIVOLTE_HOST}

    port = 8290
    port = ${?DIVOLTE_PORT}

    use_x_forwarded_for = false
  }

  tracking {
    party_cookie = _dvp
    party_timeout = 3652 days
    session_cookie = _dvs
    session_timeout = 30 minutes
    page_view_cookie = _dvv
  }

  incoming_request_processor {
    threads = 2
    max_write_queue = 100000
    max_enqueue_delay = 1 second
  }

  kafka_flusher {
    enabled = false

    max_write_queue = 200000
    max_enqueue_delay = 1 second
    threads = 2

    // The topic onto which events are published.
    topic = "divolte"
    topic = ${?DIVOLTE_KAFKA_TOPIC}

    // All settings in here are used as-is to configure
    // the Kafka producer.
    // See: http://kafka.apache.org/documentation.html#producerconfigs
    producer = {
      metadata.broker.list = ["localhost:9092"]
      metadata.broker.list = ${?DIVOLTE_KAFKA_BROKER_LIST}

      client.id = divolte.collector
      client.id = ${?DIVOLTE_KAFKA_CLIENT_ID}

      request.required.acks = 0
      message.send.max.retries = 5
      retry.backoff.ms = 200
    }
  }

  hdfs_flusher {
    enabled = true

    max_write_queue = 100000
    max_enqueue_delay = 1 second
    threads = 2

    hdfs {
      // default to file:/// (local filesystem)
      uri = "file:///"
      uri = ${?DIVOLTE_HDFS_URI}
      // defaults to 1
      replication = 1
      replication = ${?DIVOLTE_HDFS_REPLICATION}
    }

    simple_rolling_file_strategy {
      roll_every = 60 minutes
      sync_file_after_records = 1000
      sync_file_after_duration = 30 seconds

      // defaults to /tmp
      working_dir = /tmp
      publish_dir = /tmp
    }
  }

  tracking.ua_parser {
    type = caching_and_updating
    cache_size = 1000
  }
}
