apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'application'
apply plugin: 'findbugs'
apply plugin: 'pmd'
apply plugin: 'jacoco'
apply plugin: 'application'
apply plugin: 'com.github.johnrengelman.shadow'

defaultTasks 'clean', 'build'

sourceCompatibility = 1.8
version = '0.1-SNAPSHOT'
mainClassName = 'io.divolte.server.Server'
applicationName = 'divolte-collector'
applicationDefaultJvmArgs = [
        "-XX:+UseG1GC",
        "-Djava.awt.headless=true"
]

compileJava.options.encoding = 'UTF-8'

tasks.withType(JavaCompile) {
    options.compilerArgs << "-Xlint:deprecation"
}

repositories {
    mavenCentral()
    maven {
        url 'https://repository-saucelabs.forge.cloudbees.com/release'
    }
    mavenLocal()
}

buildscript {
    repositories {
        mavenCentral()
        jcenter()
    }
    dependencies {
        classpath group: 'com.github.jengelman.gradle.plugins', name: 'shadow', version: '1.1.1'
    }
}

dependencies {
    compile group: 'io.divolte', name: 'divolte-schema', version: version
    compile group: 'io.undertow', name: 'undertow-core', version: '1.0.16.Final'
    compile group: 'com.typesafe', name: 'config', version: '1.2.1'
    compile group: 'com.google.guava', name: 'guava', version: '17.0'
    compile group: 'org.apache.avro', name: 'avro', version: '1.7.7'
    compile (group: 'org.apache.hadoop', name:'hadoop-common', version: '2.4.1') {
        exclude group: 'jline', module: 'jline'
    }
    compile group: 'org.apache.hadoop', name:'hadoop-hdfs', version: '2.4.1'
    compile (group: 'net.sf.uadetector', name: 'uadetector-core', version: '0.9.20') {
        exclude group: 'com.google.code.findbugs', module: 'jsr305'
    }
    compile group: 'net.sf.uadetector', name: 'uadetector-resources', version: '2014.08'
    compile (group: 'com.maxmind.geoip2', name: 'geoip2', version:'0.8.1') {
        // We only use DB mode, and Google's HTTP client pulls in Apache HTTP
        // client which conflicts with the version via Hadoop.
        exclude group: 'com.google.http-client', module: 'google-http-client'
    }
    compile group: 'org.apache.kafka', name:'kafka_2.10', version:'0.8.1.1'

    compile group: 'com.google.javascript', name:'closure-compiler', version:'v20140814'

    // We use the SLF4J API. At runtime, this is LogBack.
    // (We also force any dependencies that use Log4J to go via SLF4J.)
    compile group: 'org.slf4j', name: 'slf4j-api', version: '1.7.7'
    runtime group: 'ch.qos.logback', name: 'logback-classic', version: '1.1.2'
    runtime group: 'org.slf4j', name: 'log4j-over-slf4j', version: '1.7.7'

    testCompile group: 'junit', name: 'junit', version: '4.11'
    testCompile group: 'org.hamcrest', name: 'hamcrest-all', version: '1.3'
    testCompile group: 'org.mockito', name: 'mockito-all', version: '1.9.5'
    testCompile group: 'com.mashape.unirest', name: 'unirest-java', version: '1.3.20'
    testCompile group: 'com.fasterxml.jackson.core', name:'jackson-databind', version: '2.4.2'
    testCompile group: 'com.saucelabs', name:'sauce_junit', version: '2.1.3'
    testCompile group: 'org.seleniumhq.selenium', name:'selenium-java', version: '2.42.2'
    testCompile group: 'com.github.detro.ghostdriver', name: 'phantomjsdriver', version: '1.0.4'
}

configurations {
    // Exclude all traces of Log4J via transitive dependencies.
    // (At runtime these are redirected over SLF4J.)
    all*.exclude group: 'org.slf4j', module: 'slf4j-log4j12'
    all*.exclude group: 'log4j', module: 'log4j'
}

shadowJar {
    mergeServiceFiles()
}

findbugs {
    toolVersion = "3.0.0"
}

pmd {
    toolVersion = "5.1.3"
}

jacoco {
    toolVersion = "0.7.1.201405082137"
}

// For now we prefer to have a HTML report instead of XML.
findbugsMain.reports {
    xml.enabled = true
    html.enabled = false
}
findbugsTest.reports {
    xml.enabled = true
    html.enabled = false
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.1'
}

def confDir = ""
run {
    try {
        confDir = System.getenv("HADOOP_CONF_DIR")
        classpath += files(confDir)
    } catch (NullPointerException nphc) {
        try {
            confDir = System.getenv("YARN_CONF_DIR")
            classpath += files(confDir)
        } catch (NullPointerException npyc) {
            // Do nothing
        }
    }
}

task processUserDoc {
    ext.source = file("docs")
    ext.sphinxDir = new File(buildDir, "sphinx")
    inputs.dir source
    outputs.dir sphinxDir
}

import org.apache.tools.ant.filters.ReplaceTokens

processUserDoc << {
    // Copy/replace @version@
    copy {
        from(source) {
            filter(ReplaceTokens, tokens: ["version": version])
        }
        into sphinxDir
        exclude "**/*.png"
    }
    // Copy images (no replacement)
    copy {
        from(source)
        into sphinxDir
        include "**/*.png"
    }
}

task userDoc(dependsOn: processUserDoc, type: Exec) {
    ext.sphinxDir = processUserDoc.sphinxDir
    ext.htmlDocDir = new File(buildDir, "userdoc/html")
    inputs.dir sphinxDir
    outputs.dir htmlDocDir

    workingDir sphinxDir

    executable "sphinx-build"
    args '-b', 'html', sphinxDir, htmlDocDir
}
